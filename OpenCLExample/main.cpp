/*
 * First Example using OpenCL
 * https://developer.apple.com/library/archive/documentation/Performance/Conceptual/OpenCL_MacProgGuide/ExampleHelloWorld/Example_HelloWorld.html#//apple_ref/doc/uid/TP40008312-CH112-SW3
 *
 * Documentation is quite ropey, as always.
 *
 */
//==============================================================================
#include <iostream>
#include <OpenCL/opencl.h>
#include "square_kernel.cl.h"    // generated by Xcode on first build
#include "vector_add_kernel.cl.h"
//==============================================================================
#define NUM_VALUES 1024 // Hard-coded number of values to test, for convenience.
//==============================================================================
/** A utility function that checks that our kernel execution performs the
 requested work over the entire range of data. */
static int validate(cl_float* input, cl_float* output)
{
    for (int i = 0; i < NUM_VALUES; i++)
    {
        if ( output[i] != (input[i] * input[i]) ) // The kernel was supposed to square each value.
        {
            printf("Error: Element %d did not match expected output.\n", i);
            printf("       Saw %1.4f, expected %1.4f\n", output[i], input[i] * input[i]);
            fflush(stdout);
            return 0;
        }
        else
        {
        printf("%.2f\n", output[i]);
        }
    }
    return 1;
}
//==============================================================================
int firstKernel();
int secondKernel(); // defined below
//==============================================================================
int main (int argc, const char * argv[])
{
    firstKernel();
    secondKernel();
    return 0;
}

//==============================================================================
int firstKernel()
{
    // First, try to obtain a dispatch queue that can send work to the
    // GPU in our system.
    dispatch_queue_t queue = gcl_create_dispatch_queue(CL_DEVICE_TYPE_GPU, NULL); // 2
    
    // In the event that our system does NOT have an OpenCL-compatible GPU,
    // we can use the OpenCL CPU compute device instead.
    if (queue == NULL)
    {
        queue = gcl_create_dispatch_queue(CL_DEVICE_TYPE_CPU, NULL);
    }
    
    // This is not required, but let's print out the name of the device
    // we are using to do work.  We could use the same function,
    // clGetDeviceInfo, to obtain all manner of information about the device.
    char name[128];
    cl_device_id gpu = gcl_get_device_id_with_dispatch_queue(queue);
    clGetDeviceInfo(gpu, CL_DEVICE_NAME, 128, name, NULL);
    printf("Created a dispatch queue using the %s\n", name);
    
    //--------------------------------------------------------------------------
    // Generate test data
    int dataSize = sizeof(cl_float) * NUM_VALUES;
    cl_float* test_in = new cl_float[sizeof(cl_float) * NUM_VALUES];
    for (int i = 0; i < NUM_VALUES; i++)
    {
        test_in[i] = (cl_float)i;
    }
    //--------------------------------------------------------------------------
    // Once the computation using CL is done, will have to read the results
    // back into our application's memory space.  Allocate some space for that.
    float* test_out = new float[dataSize];
    
    // The test kernel takes two parameters: an input float array and an
    // output float array.  We can't send the application's buffers above, since
    // our CL device operates on its own memory space.  Therefore, we allocate
    // OpenCL memory for doing the work.  Notice that for the input array,
    // we specify CL_MEM_COPY_HOST_PTR and provide the fake input data we
    // created above.  This tells OpenCL to copy the data into its memory
    // space before it executes the kernel.                               // 3
    void* mem_in  = gcl_malloc(dataSize, test_in,
                               CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR);
    
    // The output array is not initalized; we're going to fill it up when
    // we execute our kernel.                                             // 4
    void* mem_out = gcl_malloc(dataSize, NULL, CL_MEM_WRITE_ONLY);
    
    //--------------------------------------------------------------------------
    // Apple Code Block: Basically a lambda function
    void(^kernelBlock)() =
    ^{
        size_t wgs;
        gcl_get_kernel_block_workgroup_info(square_kernel, CL_KERNEL_WORK_GROUP_SIZE, sizeof(wgs), &wgs, NULL);
        cl_ndrange range =  // 6
        {
            1,                  // The number of dimensions to use.
            {0, 0, 0},          // Offset in each dimension.  To specify in the test case // 7
            {NUM_VALUES, 0, 0}, // global range: how many items IN TOTAL in each dimension to process.
            {wgs, 0, 0}         // Local size of each workgroup.
        };
        square_kernel(&range,(cl_float*)mem_in, (cl_float*)mem_out); // 8
        gcl_memcpy(test_out, mem_out, dataSize);
    };
    
    dispatch_sync(queue, kernelBlock);
    //--------------------------------------------------------------------------
    if (validate(test_in, test_out)) // Check to see if the kernel did what it was supposed to:
    {
        
        printf("All values were properly squared.\n");
    }
    //--------------------------------------------------------------------------
    gcl_free(mem_in); // Don't forget to free up the CL device's memory when you're done. // 10
    gcl_free(mem_out);
    free(test_in); // And the same goes for system memory, as usual.
    free(test_out);
    dispatch_release(queue); // Finally, release your queue just as you would any GCD queue.    // 11
    //--------------------------------------------------------------------------
    return 0;
}
//==============================================================================
/** # OpenCL Example from
 
 @link https://www.eriksmistad.no/getting-started-with-opencl-and-gpu-computing/ @/link
 
 altered to work with macOS
 */
int secondKernel()
{
    //--------------------------------------------------------------------------
    dispatch_queue_t queue = gcl_create_dispatch_queue(CL_DEVICE_TYPE_GPU, NULL); // 2
    if (queue == NULL)
    {
        queue = gcl_create_dispatch_queue(CL_DEVICE_TYPE_CPU, NULL);
    }
    //--------------------------------------------------------------------------
    char name[128];
    cl_device_id gpu = gcl_get_device_id_with_dispatch_queue(queue);
    clGetDeviceInfo(gpu, CL_DEVICE_NAME, 128, name, NULL);
    printf("Created a dispatch queue using the %s\n", name);
    //--------------------------------------------------------------------------
    // generate test data
    const int LIST_SIZE = 1024;
    const int dataSize = sizeof(cl_int)*LIST_SIZE;
    cl_int* A = new cl_int[dataSize];
    cl_int* B = new cl_int[dataSize];
    for(int i = 0; i < LIST_SIZE; i++)
    {
        cl_int j = (cl_int)i;
        A[i] = j;
        B[i] = LIST_SIZE - j;
    }
    //--------------------------------------------------------------------------
    cl_int* test_out = new cl_int[dataSize];
    
    void* memoryBufA  = gcl_malloc(dataSize, A, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR);
    void* memoryBufB  = gcl_malloc(dataSize, B, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR);
    void* mem_out = gcl_malloc(dataSize, NULL, CL_MEM_WRITE_ONLY);
    
    //--------------------------------------------------------------------------
    // Apple Code Block: Basically a lambda function
    void(^kernelBlock)() =
    ^{
        size_t wgs;
        gcl_get_kernel_block_workgroup_info(square_kernel, CL_KERNEL_WORK_GROUP_SIZE, sizeof(wgs), &wgs, NULL);
        cl_ndrange range =  // 6
        {
            1,                  // The number of dimensions to use.
            {0, 0, 0},          // Offset in each dimension.  To specify in the test case // 7
            {NUM_VALUES, 0, 0}, // global range: how many items IN TOTAL in each dimension to process.
            {wgs, 0, 0}         // Local size of each workgroup.
        };
        vector_add_kernel(&range,(cl_int*)memoryBufA, (cl_int*)memoryBufB, (cl_int*)mem_out); // 8
        gcl_memcpy(test_out, mem_out, dataSize);
    };
    
    dispatch_sync(queue, kernelBlock);
    //--------------------------------------------------------------------------
    // Insert Validation Function
    //--------------------------------------------------------------------------
    gcl_free(memoryBufA); // Don't forget to free up the CL device's memory when you're done. // 10
    gcl_free(memoryBufB);
    gcl_free(mem_out);
    free(A); // And the same goes for system memory, as usual.
    free(B); // And the same goes for system memory, as usual.
    free(test_out);
    dispatch_release(queue); // Finally, release your queue just as you would any GCD queue.    // 11
    //--------------------------------------------------------------------------
    return 0;
}
/*
 Notes:
 
 1.     Include the header file that contains the kernel block declaration. The name of the header file for a .cl file will be the name of the .cl file with .h appended to it. For example, if the .cl file is named mykernel.cl, the header file you must include will be mykernel.cl.h.
 2.     Call gcl_create_dispatch_queue to create the dispatch queue.
 3.     Create memory objects to hold input and output data and write input data to the input objects. Allocate an array on the OpenCL device from which to read kernel results back into host memory. Use gcl_malloc and make sure to use the OpenCL size of the datatype being returned. For example, write gcl_malloc(sizeof(cl_float) * NUM_VALUES. Because the CL device operates on its own memory space, allocate OpenCL memory for the input data upon which the kernel will work. Specify CL_MEM_COPY_HOST_PTR to tell OpenCL to copy over the input data from host memory into its memory space before it executes the kernel.
 4.     Allocate OpenCL memory in which the kernel will store its results.
 5.     Dispatch your kernel block using one of the dispatch commands and the queue you created above. In your dispatch call, you can specify workgroup parameters.
 6.     Describe the data parallel range (the ndrange) over which to execute the kernel in the cl_ndrange structure. OpenCL always executes kernels in a data parallel fashion—that is, instances of the same kernel (work items) execute on different portions of the total data set. Each work item is responsible for executing the kernel once and operating on its assigned portion of the data set. You use the cl_ndrange field to specify how the workgroups are to be organized. For more information, see Specifying How To Divide Up A Dataset.
 
 7.     Always pass an offset for each of three dimensions even though the workgroup may have fewer than three dimensions. See Specifying How To Divide Up A Dataset for more information.
 8.     Call the kernel as you would call a function. Pass the ndrange as the first parameter, followed by the expected kernel parameters. Case the void* types to the expected OpenCL types. Remember, if you use float in your kernel, that's a cl_float from the application's perspective. The call to the kernel will look something like this:
 kernelName(
 &ndrange,
 (cl_datatype*)inputArray,
 (cl_datatype*)outputArray);
 9.     Retrieve the data from the OpenCL device's memory space with gcl_memcpy. The output computed by the kernel is copied over to the host application's memory space.
 10.    Free OpenCL memory objects.
 11.    Call dispatch_release(...) on the dispatch queue you created with gcl_create_dispatch_queue(...) once you are done with it.
 */
